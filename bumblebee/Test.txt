git clone https://github.com/AntCPLab/OpenBumbleBee.git

1. Install Dependencies (Ubuntu 22.04)
First follow SPUâ€™s installation instructions to install dependencies and set up the Python environment.
Then activate the conda environment and execute:
python3 -m pip install -r requirements-dev.txt

Note: There is a bug in jax version. We must install jax[cpu]==0.4.16 instead of 0.4.26.
Then install transformers:
pip install 'transformers[flax]'

After installation, JAX and JAXLIB may automatically downgrade to 0.4.13. Manually re-upgrade them to 0.4.16.
Then modify the Python library code in your environment:
(miniconda3/envs/bumblebee/lib/python3.10/site-packages)

2. Build the Program
bazel build -c opt examples/python/ml/flax_bert/... --jobs 32

3. Run BERT
pip install datasets
env SPU_BB_SET_IEQUAL_BITS=15 bazel run -c opt //examples/python/utils:nodectl -- --config `pwd`/examples/python/conf/2pc.json up
env SPU_BB_SET_IEQUAL_BITS=15 bazel run -c opt //examples/python/ml/flax_bert -- --config `pwd`/examples/python/conf/2pc.json

4. Modify Input Token Length to 128
In flax_bert.py, change:
encoded = tokenizer(
    features,
    max_length=128,
    padding="max_length",
    truncation=True,
    return_tensors="jax",
)
input_ids = encoded["input_ids"]
attention_masks = encoded["attention_mask"]

5. Modify 2pc.json configuration to adjust thread count
"runtime_config": {
    "protocol": "CHEETAH",
    "field": "FM64",
    "enable_pphlo_profile": true,
    "enable_hal_profile": true,
    "fxp_exp_mode": 0,
    "fxp_exp_iters": 4,
    "fxp_fraction_bits": 16,
    "experimental_enable_colocated_optimization": true,
    "cheetah_2pc_config": {
        "enable_mul_lsb_error": true,
        "approx_less_precision": 4,
        "ot_kind": "YACL_Ferret"
    },
    "max_concurrency": 16
},
"link_desc": {
    "recv_timeout_ms": 300000,
    "connect_retry_times": 30,
    "connect_retry_interval_ms": 500,
    "brpc_timeout_ms": 300000
}
