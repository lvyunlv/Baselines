>>> Evaluating Bert
-> Role: 1
-> Address: 127.0.0.1
-> Port: 8000
<<<

> Setup Linear
> HE instance initialized: 
-> Poly Mod Degree: 8192
-> Coeff Mod: 54 54 55 55 
-> Plaintext Mod: 536903681(29 bits)

> HE instance initialized: 
-> Poly Mod Degree: 8192
-> Coeff Mod: 60 60 60 
-> Plaintext Mod: 557057(19 bits)

> HE instance initialized: 
-> Poly Mod Degree: 8192
-> Coeff Mod: 54 54 55 55 
-> Plaintext Mod: 4295049217(32 bits)

> Setup NonLinear
> Loading and preprocessing weights on server
> [TIMING]: Loading Model takes: 0.585175sec
> [TIMING]: Model Preprocessing takes: 27.3604sec
> Bert intialized done!

==>> Inference sample #0
> Receive input cts from client 
> --- Entering Attention Layers ---
-> Layer - 0: Linear #1 HE
-> Layer - 0: Linear #1 done HE
-> Layer - 0: Linear #2 HE
-> Layer - 0: Linear #2 HE done 
-> Layer - 0: Linear #3 HE
-> Layer - 0: Linear #3 HE done 
-> Layer - 0: Linear #4 HE 
-> Layer - 0: Linear #4 HE done
-> Layer - 1: Linear #1 HE
-> Layer - 1: Linear #1 done HE
-> Layer - 1: Linear #2 HE
-> Layer - 1: Linear #2 HE done 
-> Layer - 1: Linear #3 HE
-> Layer - 1: Linear #3 HE done 
-> Layer - 1: Linear #4 HE 
-> Layer - 1: Linear #4 HE done
-> Layer - 2: Linear #1 HE
-> Layer - 2: Linear #1 done HE
-> Layer - 2: Linear #2 HE
-> Layer - 2: Linear #2 HE done 
-> Layer - 2: Linear #3 HE
-> Layer - 2: Linear #3 HE done 
-> Layer - 2: Linear #4 HE 
-> Layer - 2: Linear #4 HE done
-> Layer - 3: Linear #1 HE
-> Layer - 3: Linear #1 done HE
-> Layer - 3: Linear #2 HE
-> Layer - 3: Linear #2 HE done 
-> Layer - 3: Linear #3 HE
-> Layer - 3: Linear #3 HE done 
-> Layer - 3: Linear #4 HE 
-> Layer - 3: Linear #4 HE done
-> Layer - 4: Linear #1 HE
-> Layer - 4: Linear #1 done HE
-> Layer - 4: Linear #2 HE
-> Layer - 4: Linear #2 HE done 
-> Layer - 4: Linear #3 HE
-> Layer - 4: Linear #3 HE done 
-> Layer - 4: Linear #4 HE 
-> Layer - 4: Linear #4 HE done
-> Layer - 5: Linear #1 HE
-> Layer - 5: Linear #1 done HE
-> Layer - 5: Linear #2 HE
-> Layer - 5: Linear #2 HE done 
-> Layer - 5: Linear #3 HE
-> Layer - 5: Linear #3 HE done 
-> Layer - 5: Linear #4 HE 
-> Layer - 5: Linear #4 HE done
-> Layer - 6: Linear #1 HE
-> Layer - 6: Linear #1 done HE
-> Layer - 6: Linear #2 HE
-> Layer - 6: Linear #2 HE done 
-> Layer - 6: Linear #3 HE
-> Layer - 6: Linear #3 HE done 
-> Layer - 6: Linear #4 HE 
-> Layer - 6: Linear #4 HE done
-> Layer - 7: Linear #1 HE
-> Layer - 7: Linear #1 done HE
-> Layer - 7: Linear #2 HE
-> Layer - 7: Linear #2 HE done 
-> Layer - 7: Linear #3 HE
-> Layer - 7: Linear #3 HE done 
-> Layer - 7: Linear #4 HE 
-> Layer - 7: Linear #4 HE done
-> Layer - 8: Linear #1 HE
-> Layer - 8: Linear #1 done HE
-> Layer - 8: Linear #2 HE
-> Layer - 8: Linear #2 HE done 
-> Layer - 8: Linear #3 HE
-> Layer - 8: Linear #3 HE done 
-> Layer - 8: Linear #4 HE 
-> Layer - 8: Linear #4 HE done
-> Layer - 9: Linear #1 HE
-> Layer - 9: Linear #1 done HE
-> Layer - 9: Linear #2 HE
-> Layer - 9: Linear #2 HE done 
-> Layer - 9: Linear #3 HE
-> Layer - 9: Linear #3 HE done 
-> Layer - 9: Linear #4 HE 
-> Layer - 9: Linear #4 HE done
-> Layer - 10: Linear #1 HE
-> Layer - 10: Linear #1 done HE
-> Layer - 10: Linear #2 HE
-> Layer - 10: Linear #2 HE done 
-> Layer - 10: Linear #3 HE
-> Layer - 10: Linear #3 HE done 
-> Layer - 10: Linear #4 HE 
-> Layer - 10: Linear #4 HE done
-> Layer - 11: Linear #1 HE
-> Layer - 11: Linear #1 done HE
-> Layer - 11: Linear #2 HE
-> Layer - 11: Linear #2 HE done 
-> Layer - 11: Linear #3 HE
-> Layer - 11: Linear #3 HE done 
-> Layer - 11: Linear #4 HE 
-> Layer - 11: Linear #4 HE done
-> Sharing Pooling and Classification params...
-> Layer - Pooling
-> Layer - Classification
> [TIMING]: linear1 takes 136.976 sec
> [TIMING]: linear2 takes 15.614 sec
> [TIMING]: linear3 takes 49.2839 sec
> [TIMING]: linear4 takes 50.8157 sec
> [TIMING]: softmax takes 869.461 sec
> [TIMING]: pruning takes 0.00754487 sec
> [TIMING]: mul v takes 60.1531 sec
> [TIMING]: gelu takes 766.811 sec
> [TIMING]: ln_1 takes 554.71 sec
> [TIMING]: ln_2 takes 553.004 sec
> [TIMING]: tanh takes 13.6206 sec
> [TIMING]: repacking takes 15.6875 sec
> [TIMING]: gt_sub takes 324.02 sec
> [TIMING]: shift takes 218.339 sec
> [TIMING]: conversion takes 52.216 sec
> [TIMING]: ln_share takes 0.00843633 sec
> [TIMING]: Pool/Class takes 45.7607 sec
> [NETWORK]: Linear 1 consumes: 33.8918 Mbytes
> [NETWORK]: Linear 2 consumes: 18.1593 Mbytes
> [NETWORK]: Linear 3 consumes: 72.0747 Mbytes
> [NETWORK]: Linear 4 consumes: 18.1593 Mbytes
> [NETWORK]: Softmax consumes: 8685.88 Mbytes
> [NETWORK]: GELU consumes: 8830.03 Mbytes
> [NETWORK]: Layer Norm 1 consumes: 3579.47 Mbytes
> [NETWORK]: Layer Norm 2 consumes: 3579.47 Mbytes
> [NETWORK]: Tanh consumes: 8.32031 Mbytes
> [NETWORK]: Softmax * V: 16.9458 Mbytes
> [NETWORK]: Pruning: 0 Mbytes
> [NETWORK]: Shift consumes: 2007.79 Mbytes
> [NETWORK]: gt_sub consumes: 3225.47 Mbytes
> [NETWORK]: Pooling / C consumes: 296.388 Mbytes
> [NETWORK]: Linear 1 consumes: 23 rounds
> [NETWORK]: Linear 2 consumes: 24 rounds
> [NETWORK]: Linear 3 consumes: 24 rounds
> [NETWORK]: Linear 4 consumes: 24 rounds
> [NETWORK]: Softmax consumes: 89088 rounds
> [NETWORK]: GELU consumes: 33792 rounds
> [NETWORK]: Layer Norm 1 consumes: 83736 rounds
> [NETWORK]: Layer Norm 2 consumes: 83736 rounds
> [NETWORK]: Tanh consumes: 3520 rounds
> [NETWORK]: Softmax * V: 24 rounds
> [NETWORK]: Pruning: 0 rounds
> [NETWORK]: Shift consumes: 18368 rounds
> [NETWORK]: gt_sub consumes: 16864 rounds
> [NETWORK]: Pooling / C consumes: 988 rounds
-> End to end takes: 3660.66sec
